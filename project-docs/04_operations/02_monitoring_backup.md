---
title: "ç›£è¦–ãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"
version: "1.0"
last_updated: "2025-06-23"
author: "mcp starter"
reviewers: []
related_docs: ["01_operations_manual.md", "03_migration_plan.md"]
status: "approved"
dependencies:
  upstream: ["01_operations_manual.md", "02_design/03_database_design.md"]
  downstream: ["03_migration_plan.md"]
impact_level: "high"
---

# ç›£è¦–ãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

## 1. æ¦‚è¦

### 1.1 ç›®çš„
FastMCPã‚¹ã‚¿ãƒ¼ã‚¿ãƒ¼ã‚­ãƒƒãƒˆã®å®‰å®šé‹ç”¨ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã€åŒ…æ‹¬çš„ãªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥ã‚’å®šç¾©ã—ã¾ã™ã€‚åˆå­¦è€…ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä¿è­·ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã®å¯ç”¨æ€§ã‚’ç¢ºä¿ã—ã¾ã™ã€‚

### 1.2 ç›£è¦–å¯¾è±¡
- FastMCPã‚µãƒ¼ãƒãƒ¼ã®ç¨¼åƒçŠ¶æ³
- SSE/STDIOé€šä¿¡çŠ¶æ³
- å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ãƒ»ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ç®¡ç†
- SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
- ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹

### 1.3 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ–¹é‡
```yaml
ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥:
  ç›®æ¨™å¾©æ—§æ™‚é–“(RTO): 30åˆ†ä»¥å†…
  ç›®æ¨™å¾©æ—§æ™‚ç‚¹(RPO): 1æ™‚é–“ä»¥å†…
  ä¿æŒæœŸé–“: 30æ—¥é–“
  ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é »åº¦: æ—¥æ¬¡è‡ªå‹•å®Ÿè¡Œ
  æ¤œè¨¼é »åº¦: é€±æ¬¡å¾©æ—§ãƒ†ã‚¹ãƒˆ
```

## 2. ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

### 2.1 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
```python
# realtime_monitor.py
import asyncio
import json
import sqlite3
import psutil
from datetime import datetime, timedelta
from typing import Dict, List

class RealtimeMonitor:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, config):
        self.config = config
        self.alert_thresholds = {
            "cpu_usage": 85.0,
            "memory_usage": 80.0,
            "disk_usage": 90.0,
            "response_time": 3.0,
            "error_rate": 5.0
        }
        self.monitoring_active = False
    
    async def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        self.monitoring_active = True
        
        # ä¸¦è¡Œç›£è¦–ã‚¿ã‚¹ã‚¯é–‹å§‹
        tasks = [
            asyncio.create_task(self.monitor_system_resources()),
            asyncio.create_task(self.monitor_mcp_server()),
            asyncio.create_task(self.monitor_learning_system()),
            asyncio.create_task(self.monitor_database()),
            asyncio.create_task(self.alert_processor())
        ]
        
        await asyncio.gather(*tasks)
    
    async def monitor_system_resources(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–"""
        while self.monitoring_active:
            try:
                metrics = {
                    "timestamp": datetime.now().isoformat(),
                    "cpu_percent": psutil.cpu_percent(interval=1),
                    "memory": {
                        "percent": psutil.virtual_memory().percent,
                        "available": psutil.virtual_memory().available,
                        "used": psutil.virtual_memory().used
                    },
                    "disk": {
                        "percent": psutil.disk_usage('/').percent,
                        "free": psutil.disk_usage('/').free
                    },
                    "network": dict(psutil.net_io_counters()._asdict())
                }
                
                # ã‚¢ãƒ©ãƒ¼ãƒˆåˆ¤å®š
                await self.check_resource_alerts(metrics)
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜
                await self.save_metrics("system_resources", metrics)
                
            except Exception as e:
                print(f"System monitoring error: {e}")
            
            await asyncio.sleep(30)  # 30ç§’é–“éš”
    
    async def monitor_mcp_server(self):
        """MCPã‚µãƒ¼ãƒãƒ¼ç›£è¦–"""
        while self.monitoring_active:
            try:
                # ã‚µãƒ¼ãƒãƒ¼ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
                health_status = await self.check_server_health()
                
                # é€šä¿¡çµ±è¨ˆ
                comm_stats = await self.collect_communication_stats()
                
                metrics = {
                    "timestamp": datetime.now().isoformat(),
                    "server_status": health_status,
                    "communication": comm_stats
                }
                
                # ã‚¢ãƒ©ãƒ¼ãƒˆåˆ¤å®š
                if not health_status["healthy"]:
                    await self.send_alert("server_down", "MCPã‚µãƒ¼ãƒãƒ¼ãŒå¿œç­”ã—ã¾ã›ã‚“", "critical")
                
                if comm_stats["error_rate"] > self.alert_thresholds["error_rate"]:
                    await self.send_alert("high_error_rate", 
                                        f"ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã„: {comm_stats['error_rate']:.1f}%", "warning")
                
                await self.save_metrics("mcp_server", metrics)
                
            except Exception as e:
                print(f"MCP server monitoring error: {e}")
            
            await asyncio.sleep(60)  # 1åˆ†é–“éš”
    
    async def collect_communication_stats(self) -> Dict:
        """é€šä¿¡çµ±è¨ˆåé›†"""
        conn = sqlite3.connect(self.config["database_url"])
        cursor = conn.cursor()
        
        # éå»1æ™‚é–“ã®çµ±è¨ˆ
        one_hour_ago = datetime.now() - timedelta(hours=1)
        
        cursor.execute("""
            SELECT 
                COUNT(*) as total_requests,
                SUM(CASE WHEN status = 'error' THEN 1 ELSE 0 END) as error_count,
                AVG(response_time) as avg_response_time,
                transport_type
            FROM request_logs 
            WHERE timestamp > ? 
            GROUP BY transport_type
        """, (one_hour_ago,))
        
        results = cursor.fetchall()
        conn.close()
        
        stats = {
            "total_requests": 0,
            "error_count": 0,
            "error_rate": 0.0,
            "avg_response_time": 0.0,
            "sse_requests": 0,
            "stdio_requests": 0
        }
        
        for row in results:
            total, errors, avg_time, transport = row
            stats["total_requests"] += total
            stats["error_count"] += errors
            stats["avg_response_time"] = max(stats["avg_response_time"], avg_time or 0)
            
            if transport == "sse":
                stats["sse_requests"] = total
            elif transport == "stdio":
                stats["stdio_requests"] = total
        
        if stats["total_requests"] > 0:
            stats["error_rate"] = (stats["error_count"] / stats["total_requests"]) * 100
        
        return stats
```

### 2.2 ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
```python
# dashboard.py
from flask import Flask, render_template, jsonify
import sqlite3
import json

app = Flask(__name__)

class MonitoringDashboard:
    """ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    def __init__(self, db_path):
        self.db_path = db_path
    
    @app.route('/')
    def dashboard():
        """ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
        return render_template('dashboard.html')
    
    @app.route('/api/status')
    def get_system_status():
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³API"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æœ€æ–°ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
        cursor.execute("""
            SELECT metric_type, data, timestamp 
            FROM monitoring_metrics 
            WHERE timestamp > datetime('now', '-1 hour')
            ORDER BY timestamp DESC
        """)
        
        metrics = {}
        for row in cursor.fetchall():
            metric_type, data, timestamp = row
            if metric_type not in metrics:
                metrics[metric_type] = []
            metrics[metric_type].append({
                "data": json.loads(data),
                "timestamp": timestamp
            })
        
        conn.close()
        return jsonify(metrics)
    
    @app.route('/api/learning-stats')
    def get_learning_statistics():
        """å­¦ç¿’çµ±è¨ˆAPI"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # å­¦ç¿’çµ±è¨ˆ
        cursor.execute("""
            SELECT 
                COUNT(DISTINCT user_id) as active_users,
                COUNT(*) as total_sessions,
                AVG(completion_rate) as avg_completion
            FROM user_progress 
            WHERE last_updated > datetime('now', '-24 hours')
        """)
        
        stats = cursor.fetchone()
        
        # ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«åˆ¥çµ±è¨ˆ
        cursor.execute("""
            SELECT t.title, COUNT(up.id) as attempts, 
                   AVG(up.completion_rate) as avg_completion
            FROM tutorials t
            LEFT JOIN user_progress up ON t.id = up.tutorial_id
            WHERE up.last_updated > datetime('now', '-7 days')
            GROUP BY t.id, t.title
        """)
        
        tutorial_stats = cursor.fetchall()
        
        conn.close()
        
        return jsonify({
            "active_users": stats[0] or 0,
            "total_sessions": stats[1] or 0,
            "avg_completion": stats[2] or 0,
            "tutorial_stats": tutorial_stats
        })
```

## 3. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ 

### 3.1 è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
```bash
#!/bin/bash
# backup_system.sh - è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

# è¨­å®š
BACKUP_DIR="/backup/fastmcp"
DB_PATH="fastmcp.db"
CONFIG_DIR="config"
LOGS_DIR="logs"
RETENTION_DAYS=30

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
perform_backup() {
    local backup_timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_path="$BACKUP_DIR/$backup_timestamp"
    
    echo "ğŸ”„ FastMCP ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹: $backup_timestamp"
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    mkdir -p "$backup_path"
    
    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    echo "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸­..."
    sqlite3 "$DB_PATH" ".backup '$backup_path/fastmcp.db'"
    if [ $? -eq 0 ]; then
        echo "âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†"
    else
        echo "âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—"
        exit 1
    fi
    
    # 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    echo "âš™ï¸  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸­..."
    tar -czf "$backup_path/config.tar.gz" "$CONFIG_DIR"
    echo "âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†"
    
    # 3. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆç›´è¿‘7æ—¥åˆ†ï¼‰
    echo "ğŸ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸­..."
    find "$LOGS_DIR" -name "*.log" -mtime -7 | tar -czf "$backup_path/logs.tar.gz" -T -
    echo "âœ… ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†"
    
    # 4. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼
    echo "ğŸ” ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼ä¸­..."
    if verify_backup "$backup_path"; then
        echo "âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼æˆåŠŸ"
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒ…å ±è¨˜éŒ²
        cat > "$backup_path/backup_info.json" << EOF
{
    "timestamp": "$backup_timestamp",
    "backup_type": "full",
    "database_size": "$(du -h "$backup_path/fastmcp.db" | cut -f1)",
    "config_size": "$(du -h "$backup_path/config.tar.gz" | cut -f1)",
    "logs_size": "$(du -h "$backup_path/logs.tar.gz" | cut -f1)",
    "verification": "passed"
}
EOF
        
    else
        echo "âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼å¤±æ•—"
        rm -rf "$backup_path"
        exit 1
    fi
    
    # 5. å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    cleanup_old_backups
    
    echo "ğŸ‰ FastMCP ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: $backup_path"
}

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼
verify_backup() {
    local backup_path="$1"
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    sqlite3 "$backup_path/fastmcp.db" "PRAGMA integrity_check;" | grep -q "ok"
    if [ $? -ne 0 ]; then
        echo "âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å¤±æ•—"
        return 1
    fi
    
    # å¿…é ˆãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèª
    local required_tables="users tutorials user_progress"
    for table in $required_tables; do
        count=$(sqlite3 "$backup_path/fastmcp.db" "SELECT COUNT(*) FROM sqlite_master WHERE type='table' AND name='$table'")
        if [ "$count" -eq 0 ]; then
            echo "âŒ å¿…é ˆãƒ†ãƒ¼ãƒ–ãƒ« '$table' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            return 1
        fi
    done
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
    if [ ! -f "$backup_path/config.tar.gz" ] || [ ! -f "$backup_path/logs.tar.gz" ]; then
        echo "âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸å®Œå…¨ã§ã™"
        return 1
    fi
    
    return 0
}

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
cleanup_old_backups() {
    echo "ğŸ§¹ å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­..."
    find "$BACKUP_DIR" -type d -name "20*" -mtime +$RETENTION_DAYS -exec rm -rf {} \;
    echo "âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†"
}

# å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
incremental_backup() {
    local last_backup=$(find "$BACKUP_DIR" -type d -name "20*" | sort | tail -1)
    local backup_timestamp=$(date +%Y%m%d_%H%M%S)_incremental
    local backup_path="$BACKUP_DIR/$backup_timestamp"
    
    echo "ğŸ”„ å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹: $backup_timestamp"
    
    mkdir -p "$backup_path"
    
    # å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    if [ -n "$last_backup" ]; then
        find . -newer "$last_backup/backup_info.json" -type f \
            -path "./fastmcp.db*" -o -path "./config/*" -o -path "./logs/*" \
            | tar -czf "$backup_path/incremental.tar.gz" -T -
    else
        echo "âš ï¸  ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œã—ã¾ã™"
        perform_backup
        return
    fi
    
    echo "âœ… å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: $backup_path"
}
```

### 3.2 å¾©æ—§æ‰‹é †
```bash
#!/bin/bash
# restore_system.sh - ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

# å¾©æ—§å®Ÿè¡Œ
restore_from_backup() {
    local backup_path="$1"
    local restore_type="${2:-full}"  # full or selective
    
    echo "ğŸ”„ FastMCP ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§é–‹å§‹"
    echo "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‘ã‚¹: $backup_path"
    echo "å¾©æ—§ã‚¿ã‚¤ãƒ—: $restore_type"
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼
    if [ ! -d "$backup_path" ]; then
        echo "âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $backup_path"
        exit 1
    fi
    
    # ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ åœæ­¢
    echo "ğŸ›‘ ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ä¸­..."
    stop_fastmcp_server
    
    # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿é€€é¿
    local emergency_backup="emergency_backup_$(date +%Y%m%d_%H%M%S)"
    mkdir -p "$emergency_backup"
    cp fastmcp.db "$emergency_backup/" 2>/dev/null || true
    cp -r config "$emergency_backup/" 2>/dev/null || true
    
    # å¾©æ—§å®Ÿè¡Œ
    case $restore_type in
        "full")
            restore_full_system "$backup_path"
            ;;
        "database")
            restore_database_only "$backup_path"
            ;;
        "config")
            restore_config_only "$backup_path"
            ;;
        *)
            echo "âŒ ä¸æ­£ãªå¾©æ—§ã‚¿ã‚¤ãƒ—: $restore_type"
            exit 1
            ;;
    esac
    
    # ã‚·ã‚¹ãƒ†ãƒ å†èµ·å‹•
    echo "ğŸš€ ã‚·ã‚¹ãƒ†ãƒ å†èµ·å‹•ä¸­..."
    start_fastmcp_server
    
    # å¾©æ—§æ¤œè¨¼
    echo "ğŸ” å¾©æ—§æ¤œè¨¼ä¸­..."
    if verify_system_health; then
        echo "âœ… ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§å®Œäº†"
        
        # ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤
        rm -rf "$emergency_backup"
    else
        echo "âŒ ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§æ¤œè¨¼å¤±æ•— - ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©æ—§ä¸­..."
        restore_emergency_backup "$emergency_backup"
    fi
}

# ãƒ•ãƒ«å¾©æ—§
restore_full_system() {
    local backup_path="$1"
    
    echo "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©æ—§ä¸­..."
    cp "$backup_path/fastmcp.db" "fastmcp.db"
    
    echo "âš™ï¸  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å¾©æ—§ä¸­..."
    tar -xzf "$backup_path/config.tar.gz" -C .
    
    echo "ğŸ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å¾©æ—§ä¸­..."
    tar -xzf "$backup_path/logs.tar.gz" -C .
    
    echo "âœ… ãƒ•ãƒ«å¾©æ—§å®Œäº†"
}

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã¿å¾©æ—§
restore_database_only() {
    local backup_path="$1"
    
    echo "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã¿å¾©æ—§ä¸­..."
    
    # ç¾åœ¨ã®DBãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    cp fastmcp.db "fastmcp.db.before_restore" 2>/dev/null || true
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©æ—§
    cp "$backup_path/fastmcp.db" "fastmcp.db"
    
    # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    sqlite3 fastmcp.db "PRAGMA integrity_check;" | grep -q "ok"
    if [ $? -ne 0 ]; then
        echo "âŒ å¾©æ—§ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å•é¡ŒãŒã‚ã‚Šã¾ã™"
        cp "fastmcp.db.before_restore" "fastmcp.db" 2>/dev/null || true
        exit 1
    fi
    
    echo "âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©æ—§å®Œäº†"
}

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å¾©æ—§
restore_learning_data() {
    local backup_db="$1"
    local target_db="${2:-fastmcp.db}"
    
    echo "ğŸ“ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å¾©æ—§ä¸­..."
    
    # å­¦ç¿’é–¢é€£ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã¿å¾©æ—§
    sqlite3 "$backup_db" ".dump users" | sqlite3 "$target_db"
    sqlite3 "$backup_db" ".dump user_progress" | sqlite3 "$target_db"
    sqlite3 "$backup_db" ".dump tutorials" | sqlite3 "$target_db"
    sqlite3 "$backup_db" ".dump tutorial_steps" | sqlite3 "$target_db"
    
    echo "âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å¾©æ—§å®Œäº†"
}
```

## 4. ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 

### 4.1 ã‚¢ãƒ©ãƒ¼ãƒˆå®šç¾©
```python
# alert_system.py
import asyncio
import smtplib
from email.mime.text import MimeText
from enum import Enum
from dataclasses import dataclass
from typing import List

class AlertLevel(Enum):
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"

@dataclass
class Alert:
    level: AlertLevel
    title: str
    message: str
    timestamp: datetime
    component: str
    resolved: bool = False

class AlertManager:
    """ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, config):
        self.config = config
        self.active_alerts: List[Alert] = []
        self.alert_handlers = {
            AlertLevel.INFO: self.handle_info_alert,
            AlertLevel.WARNING: self.handle_warning_alert,
            AlertLevel.CRITICAL: self.handle_critical_alert
        }
    
    async def send_alert(self, level: AlertLevel, title: str, message: str, component: str):
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        alert = Alert(
            level=level,
            title=title,
            message=message,
            timestamp=datetime.now(),
            component=component
        )
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨˜éŒ²
        self.active_alerts.append(alert)
        
        # ãƒ¬ãƒ™ãƒ«åˆ¥å‡¦ç†
        handler = self.alert_handlers[level]
        await handler(alert)
        
        # ãƒ­ã‚°è¨˜éŒ²
        self.log_alert(alert)
    
    async def handle_critical_alert(self, alert: Alert):
        """ç·Šæ€¥ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†"""
        # å³åº§ã«é€šçŸ¥
        await self.send_email_notification(alert)
        await self.send_slack_notification(alert)
        
        # è‡ªå‹•å¯¾å¿œå¯èƒ½ãªå ´åˆã¯å®Ÿè¡Œ
        if alert.component == "server_down":
            await self.auto_restart_server()
        elif alert.component == "disk_full":
            await self.auto_cleanup_logs()
    
    async def auto_restart_server(self):
        """ã‚µãƒ¼ãƒãƒ¼è‡ªå‹•å†èµ·å‹•"""
        try:
            # 3å›ã¾ã§å†èµ·å‹•è©¦è¡Œ
            for attempt in range(3):
                await asyncio.sleep(10)  # 10ç§’å¾…æ©Ÿ
                
                # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
                process = await asyncio.create_subprocess_exec(
                    "python", "src/main.py",
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                
                # èµ·å‹•ç¢ºèª
                await asyncio.sleep(30)
                if await self.check_server_health():
                    await self.send_alert(AlertLevel.INFO, 
                                        "è‡ªå‹•å¾©æ—§æˆåŠŸ", 
                                        f"ã‚µãƒ¼ãƒãƒ¼ãŒæ­£å¸¸ã«èµ·å‹•ã—ã¾ã—ãŸ (è©¦è¡Œå›æ•°: {attempt + 1})",
                                        "auto_recovery")
                    return
            
            # è‡ªå‹•å¾©æ—§å¤±æ•—
            await self.send_alert(AlertLevel.CRITICAL,
                                "è‡ªå‹•å¾©æ—§å¤±æ•—",
                                "ã‚µãƒ¼ãƒãƒ¼ã®è‡ªå‹•å¾©æ—§ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•å¯¾å¿œãŒå¿…è¦ã§ã™ã€‚",
                                "auto_recovery")
        
        except Exception as e:
            await self.send_alert(AlertLevel.CRITICAL,
                                "è‡ªå‹•å¾©æ—§ã‚¨ãƒ©ãƒ¼",
                                f"è‡ªå‹•å¾©æ—§å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}",
                                "auto_recovery")
```

## 5. æ›´æ–°å±¥æ­´

| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | æ›´æ–°æ—¥ | æ›´æ–°è€… | æ›´æ–°å†…å®¹ | å½±éŸ¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ |
|---|-----|-----|----|----|
| 1.0 | 2025-06-23 | mcp starter | åˆç‰ˆä½œæˆï¼ˆFastMCPå¯¾å¿œç›£è¦–ãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ï¼‰ | 01_operations_manual.md, 03_migration_plan.md | 