---
title: "é‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«"
version: "1.0"
last_updated: "2025-06-23"
author: "mcp starter"
reviewers: []
related_docs: ["02_monitoring_backup.md", "03_migration_plan.md", "03_deployment_guide.md"]
status: "approved"
dependencies:
  upstream: ["03_development/03_deployment_guide.md", "02_design/01_system_architecture.md"]
  downstream: ["02_monitoring_backup.md", "03_migration_plan.md"]
impact_level: "high"
---

# é‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«

## 1. æ¦‚è¦

### 1.1 ç›®çš„
æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€FastMCPã‚¹ã‚¿ãƒ¼ã‚¿ãƒ¼ã‚­ãƒƒãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ—¥å¸¸é‹ç”¨ã«ãŠã‘ã‚‹æ‰‹é †ã¨æŒ‡é‡ã‚’å®šç¾©ã—ã¾ã™ã€‚åˆå­¦è€…ãŒMCPã‚µãƒ¼ãƒã‚’å®‰å®šã—ã¦é‹ç”¨ã—ã€å­¦ç¿’ç’°å¢ƒã‚’ç¶™ç¶šçš„ã«æä¾›ã§ãã‚‹ã‚ˆã†æ”¯æ´ã—ã¾ã™ã€‚

### 1.2 é‹ç”¨å¯¾è±¡
- FastMCPãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ™ãƒ¼ã‚¹ã®MCPã‚µãƒ¼ãƒ
- SSE/STDIOä¸¡æ–¹ã®é€šä¿¡æ–¹å¼
- å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ãƒ»ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ãƒ»ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ç®¡ç†
- åˆå­¦è€…å‘ã‘é‹ç”¨æ”¯æ´æ©Ÿèƒ½

### 1.3 é‹ç”¨åŸå‰‡
```yaml
é‹ç”¨åŸºæœ¬æ–¹é‡:
  å¯ç”¨æ€§: 99%ä»¥ä¸Šã®ç¨¼åƒç‡ç¶­æŒ
  å¿œç­”æ€§: 2ç§’ä»¥å†…ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“
  å­¦ç¿’ç¶™ç¶šæ€§: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¿è­·ãƒ»ç¶™ç¶šæ€§ç¢ºä¿
  åˆå­¦è€…é…æ…®: åˆ†ã‹ã‚Šã‚„ã™ã„é‹ç”¨æ‰‹é †ãƒ»ã‚¨ãƒ©ãƒ¼å¯¾å¿œ
  è‡ªå‹•åŒ–: æ‰‹å‹•ä½œæ¥­ã®æœ€å°åŒ–
```

## 2. æ—¥å¸¸é‹ç”¨æ‰‹é †

### 2.1 ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ãƒ»åœæ­¢
```bash
# åŸºæœ¬èµ·å‹•æ‰‹é †
start_server() {
    echo "ğŸš€ FastMCP Server èµ·å‹•ä¸­..."
    
    # 1. ç’°å¢ƒç¢ºèª
    check_environment
    
    # 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
    validate_config
    
    # 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
    check_database
    
    # 4. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
    if [ "$TRANSPORT_MODE" = "sse" ]; then
        python src/main.py --transport sse --port 8000 &
    else
        python src/main.py --transport stdio &
    fi
    
    SERVER_PID=$!
    echo "âœ… Server started (PID: $SERVER_PID)"
    
    # 5. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    sleep 5
    health_check
}

# å®‰å…¨ãªåœæ­¢æ‰‹é †
stop_server() {
    echo "ğŸ›‘ FastMCP Server åœæ­¢ä¸­..."
    
    # 1. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¢ºèª
    active_sessions=$(get_active_sessions)
    if [ "$active_sessions" -gt 0 ]; then
        echo "âš ï¸  ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: $active_sessions"
        echo "â° 30ç§’å¾Œã«å¼·åˆ¶åœæ­¢ã—ã¾ã™"
        sleep 30
    fi
    
    # 2. ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
    kill -TERM $SERVER_PID
    wait $SERVER_PID
    
    echo "âœ… Server stopped safely"
}

# å†èµ·å‹•æ‰‹é †
restart_server() {
    echo "ğŸ”„ FastMCP Server å†èµ·å‹•ä¸­..."
    stop_server
    sleep 3
    start_server
}
```

### 2.2 ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
```python
# health_monitor.py - å®šæœŸãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
import asyncio
import aiohttp
import sqlite3
from datetime import datetime

class HealthMonitor:
    """FastMCPã‚µãƒ¼ãƒãƒ¼ã®ãƒ˜ãƒ«ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°"""
    
    def __init__(self, config):
        self.config = config
        self.checks = {
            "server_response": self.check_server_response,
            "database_connection": self.check_database,
            "memory_usage": self.check_memory,
            "learning_system": self.check_learning_system
        }
    
    async def run_health_checks(self) -> dict:
        """å…¨ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ"""
        results = {"timestamp": datetime.now().isoformat(), "status": "healthy"}
        
        for check_name, check_func in self.checks.items():
            try:
                check_result = await check_func()
                results[check_name] = {
                    "status": "pass" if check_result["healthy"] else "fail",
                    "response_time": check_result.get("response_time", 0),
                    "details": check_result.get("details", "")
                }
                
                if not check_result["healthy"]:
                    results["status"] = "unhealthy"
                    
            except Exception as e:
                results[check_name] = {
                    "status": "error",
                    "error": str(e)
                }
                results["status"] = "unhealthy"
        
        # çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        self.log_health_status(results)
        return results
    
    async def check_server_response(self) -> dict:
        """ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯"""
        start_time = asyncio.get_event_loop().time()
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"http://{self.config['host']}:{self.config['port']}/health",
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as response:
                    response_time = asyncio.get_event_loop().time() - start_time
                    
                    return {
                        "healthy": response.status == 200,
                        "response_time": response_time,
                        "details": f"HTTP {response.status}"
                    }
        except Exception as e:
            return {
                "healthy": False,
                "response_time": 0,
                "details": f"Connection failed: {str(e)}"
            }
    
    async def check_database(self) -> dict:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒã‚§ãƒƒã‚¯"""
        try:
            conn = sqlite3.connect(self.config["database_url"])
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM users")
            user_count = cursor.fetchone()[0]
            conn.close()
            
            return {
                "healthy": True,
                "details": f"Users: {user_count}"
            }
        except Exception as e:
            return {
                "healthy": False,
                "details": f"Database error: {str(e)}"
            }
    
    async def check_learning_system(self) -> dict:
        """å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ãƒã‚§ãƒƒã‚¯"""
        try:
            # ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«æ•°ã®ç¢ºèª
            conn = sqlite3.connect(self.config["database_url"])
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM tutorials")
            tutorial_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM user_progress WHERE status = 'in_progress'")
            active_learners = cursor.fetchone()[0]
            conn.close()
            
            return {
                "healthy": tutorial_count > 0,
                "details": f"Tutorials: {tutorial_count}, Active learners: {active_learners}"
            }
        except Exception as e:
            return {
                "healthy": False,
                "details": f"Learning system error: {str(e)}"
            }
```

### 2.3 ãƒ­ã‚°ç®¡ç†
```bash
# log_management.sh - ãƒ­ã‚°ç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

# ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
rotate_logs() {
    log_dir="logs"
    max_size="100M"
    max_files=7
    
    for log_file in "$log_dir"/*.log; do
        if [ -f "$log_file" ]; then
            file_size=$(du -m "$log_file" | cut -f1)
            if [ "$file_size" -gt 100 ]; then
                echo "ğŸ“¦ Rotating $log_file (${file_size}MB)"
                
                # å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚·ãƒ•ãƒˆ
                for i in $(seq $((max_files-1)) -1 1); do
                    if [ -f "${log_file}.$i" ]; then
                        mv "${log_file}.$i" "${log_file}.$((i+1))"
                    fi
                done
                
                # ç¾åœ¨ã®ãƒ­ã‚°ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                mv "$log_file" "${log_file}.1"
                touch "$log_file"
            fi
        fi
    done
}

# ãƒ­ã‚°è§£æ
analyze_logs() {
    log_file="logs/fastmcp.log"
    echo "ğŸ“Š ãƒ­ã‚°è§£æçµæœ (éå»24æ™‚é–“)"
    echo "================================"
    
    # ã‚¨ãƒ©ãƒ¼é›†è¨ˆ
    error_count=$(grep -c "ERROR" "$log_file")
    warning_count=$(grep -c "WARNING" "$log_file")
    
    echo "âŒ ã‚¨ãƒ©ãƒ¼æ•°: $error_count"
    echo "âš ï¸  è­¦å‘Šæ•°: $warning_count"
    
    # é »å‡ºã‚¨ãƒ©ãƒ¼Top5
    echo ""
    echo "ğŸ” é »å‡ºã‚¨ãƒ©ãƒ¼ Top5:"
    grep "ERROR" "$log_file" | cut -d']' -f3- | sort | uniq -c | sort -nr | head -5
    
    # ã‚¢ã‚¯ã‚»ã‚¹çµ±è¨ˆ
    echo ""
    echo "ğŸ“ˆ ã‚¢ã‚¯ã‚»ã‚¹çµ±è¨ˆ:"
    echo "- ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—: $(grep -c "tool_call" "$log_file")"
    echo "- ãƒªã‚½ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹: $(grep -c "resource_access" "$log_file")"
    echo "- æ–°è¦å­¦ç¿’è€…: $(grep -c "new_learner" "$log_file")"
}
```

## 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç®¡ç†

### 3.1 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
```python
# performance_monitor.py
import psutil
import time
from dataclasses import dataclass
from typing import Dict, List

@dataclass
class PerformanceMetrics:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™"""
    timestamp: float
    cpu_percent: float
    memory_percent: float
    disk_usage: float
    response_time: float
    active_connections: int
    
class PerformanceMonitor:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.metrics_history: List[PerformanceMetrics] = []
        self.thresholds = {
            "cpu_percent": 80.0,
            "memory_percent": 75.0,
            "response_time": 2.0,
            "disk_usage": 85.0
        }
    
    def collect_metrics(self) -> PerformanceMetrics:
        """ç¾åœ¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’åé›†"""
        return PerformanceMetrics(
            timestamp=time.time(),
            cpu_percent=psutil.cpu_percent(interval=1),
            memory_percent=psutil.virtual_memory().percent,
            disk_usage=psutil.disk_usage('/').percent,
            response_time=self.measure_response_time(),
            active_connections=self.count_active_connections()
        )
    
    def analyze_performance(self, hours: int = 24) -> Dict:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        cutoff_time = time.time() - (hours * 3600)
        recent_metrics = [m for m in self.metrics_history if m.timestamp > cutoff_time]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        analysis = {
            "period": f"Past {hours} hours",
            "total_samples": len(recent_metrics),
            "averages": {
                "cpu_percent": sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics),
                "memory_percent": sum(m.memory_percent for m in recent_metrics) / len(recent_metrics),
                "response_time": sum(m.response_time for m in recent_metrics) / len(recent_metrics)
            },
            "peaks": {
                "max_cpu": max(m.cpu_percent for m in recent_metrics),
                "max_memory": max(m.memory_percent for m in recent_metrics),
                "max_response_time": max(m.response_time for m in recent_metrics)
            },
            "alerts": self.generate_alerts(recent_metrics)
        }
        
        return analysis
    
    def generate_alerts(self, metrics: List[PerformanceMetrics]) -> List[str]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆ"""
        alerts = []
        
        # CPUä½¿ç”¨ç‡ã‚¢ãƒ©ãƒ¼ãƒˆ
        high_cpu_samples = [m for m in metrics if m.cpu_percent > self.thresholds["cpu_percent"]]
        if len(high_cpu_samples) > len(metrics) * 0.1:  # 10%ä»¥ä¸Šã®ã‚µãƒ³ãƒ—ãƒ«ã§é–¾å€¤è¶…é
            alerts.append(f"ğŸš¨ CPUä½¿ç”¨ç‡ãŒé«˜ã„çŠ¶æ…‹ãŒç¶™ç¶š (å¹³å‡: {sum(m.cpu_percent for m in high_cpu_samples)/len(high_cpu_samples):.1f}%)")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã‚¢ãƒ©ãƒ¼ãƒˆ
        high_mem_samples = [m for m in metrics if m.memory_percent > self.thresholds["memory_percent"]]
        if len(high_mem_samples) > len(metrics) * 0.1:
            alerts.append(f"ğŸš¨ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„çŠ¶æ…‹ãŒç¶™ç¶š (å¹³å‡: {sum(m.memory_percent for m in high_mem_samples)/len(high_mem_samples):.1f}%)")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚¢ãƒ©ãƒ¼ãƒˆ
        slow_responses = [m for m in metrics if m.response_time > self.thresholds["response_time"]]
        if len(slow_responses) > len(metrics) * 0.05:  # 5%ä»¥ä¸Šã®ã‚µãƒ³ãƒ—ãƒ«ã§é–¾å€¤è¶…é
            alerts.append(f"ğŸš¨ ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒé…ã„ (å¹³å‡: {sum(m.response_time for m in slow_responses)/len(slow_responses):.2f}ç§’)")
        
        return alerts
```

### 3.2 æœ€é©åŒ–æ–½ç­–
```python
# optimization.py
class SystemOptimizer:
    """ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–"""
    
    def __init__(self):
        self.optimization_rules = {
            "database": self.optimize_database,
            "memory": self.optimize_memory,
            "cache": self.optimize_cache,
            "connections": self.optimize_connections
        }
    
    async def auto_optimize(self) -> Dict[str, str]:
        """è‡ªå‹•æœ€é©åŒ–ã®å®Ÿè¡Œ"""
        results = {}
        
        for category, optimizer in self.optimization_rules.items():
            try:
                result = await optimizer()
                results[category] = result
            except Exception as e:
                results[category] = f"Optimization failed: {str(e)}"
        
        return results
    
    async def optimize_database(self) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–"""
        # SQLiteã®æœ€é©åŒ–
        conn = sqlite3.connect("fastmcp.db")
        cursor = conn.cursor()
        
        # VACUUMï¼ˆé ˜åŸŸã®å†ç·¨æˆï¼‰
        cursor.execute("VACUUM")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å†æ§‹ç¯‰
        cursor.execute("REINDEX")
        
        # çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
        cursor.execute("ANALYZE")
        
        conn.close()
        return "Database optimized: VACUUM, REINDEX, ANALYZE completed"
    
    async def optimize_memory(self) -> str:
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–"""
        import gc
        
        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        before = len(gc.get_objects())
        collected = gc.collect()
        after = len(gc.get_objects())
        
        return f"Memory optimized: {collected} objects collected, {before-after} objects freed"
    
    async def optimize_cache(self) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–"""
        # å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã®å‰Šé™¤
        cache_manager = CacheManager()
        removed = await cache_manager.cleanup_expired()
        
        return f"Cache optimized: {removed} expired entries removed"
```

## 4. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 4.1 ä¸€èˆ¬çš„ãªå•é¡Œã¨è§£æ±ºç­–
```yaml
å•é¡Œã‚«ãƒ†ã‚´ãƒªåˆ¥å¯¾å¿œæ‰‹é †:

æ¥ç¶šã‚¨ãƒ©ãƒ¼:
  ç—‡çŠ¶: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒæ¥ç¶šã§ããªã„
  ç¢ºèªé …ç›®:
    - ã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã®ç¨¼åƒçŠ¶æ³
    - ãƒãƒ¼ãƒˆã®åˆ©ç”¨çŠ¶æ³ (netstat -tulpn | grep 8000)
    - ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®š
    - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶š
  è§£æ±ºæ‰‹é †:
    1. ã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•
    2. ãƒãƒ¼ãƒˆå¤‰æ›´ãƒ†ã‚¹ãƒˆ
    3. ãƒ­ã‚°ç¢ºèªãƒ»ã‚¨ãƒ©ãƒ¼åŸå› ç‰¹å®š

ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹:
  ç—‡çŠ¶: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒé…ã„
  ç¢ºèªé …ç›®:
    - CPUãƒ»ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
    - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚ºãƒ»ã‚¯ã‚¨ãƒªæ€§èƒ½
    - åŒæ™‚æ¥ç¶šæ•°
    - ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡
  è§£æ±ºæ‰‹é †:
    1. ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ç¢ºèª
    2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–å®Ÿè¡Œ
    3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
    4. ä¸è¦ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†

å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆ:
  ç—‡çŠ¶: å­¦ç¿’é€²æ—ãŒæ­£ã—ãè¡¨ç¤ºã•ã‚Œãªã„
  ç¢ºèªé …ç›®:
    - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§
    - å­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼çŠ¶æ³
  è§£æ±ºæ‰‹é †:
    1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    2. å­¦ç¿’é€²æ—ã®å†è¨ˆç®—
    3. ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ãƒªã‚»ãƒƒãƒˆ
```

### 4.2 ç·Šæ€¥æ™‚å¯¾å¿œæ‰‹é †
```bash
# emergency_response.sh - ç·Šæ€¥æ™‚å¯¾å¿œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

# ç·Šæ€¥åœæ­¢æ‰‹é †
emergency_stop() {
    echo "ğŸš¨ ç·Šæ€¥åœæ­¢æ‰‹é †é–‹å§‹"
    
    # 1. æ–°è¦æ¥ç¶šã®åœæ­¢
    iptables -A INPUT -p tcp --dport 8000 -j DROP
    
    # 2. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å¾…é¿
    backup_active_sessions
    
    # 3. ã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹å¼·åˆ¶çµ‚äº†
    pkill -9 -f "fastmcp"
    
    # 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    cp fastmcp.db "emergency_backup_$(date +%Y%m%d_%H%M%S).db"
    
    echo "âœ… ç·Šæ€¥åœæ­¢å®Œäº†"
}

# éšœå®³è¨ºæ–­
diagnose_system() {
    echo "ğŸ” ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­é–‹å§‹"
    
    # ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ³
    echo "=== ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ³ ==="
    ps aux | grep fastmcp
    
    # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
    echo "=== ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ ==="
    top -bn1 | grep -E "(Cpu|Mem|fastmcp)"
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ³
    echo "=== ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ³ ==="
    netstat -tulpn | grep 8000
    
    # ãƒ‡ã‚£ã‚¹ã‚¯çŠ¶æ³
    echo "=== ãƒ‡ã‚£ã‚¹ã‚¯çŠ¶æ³ ==="
    df -h
    
    # æœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
    echo "=== æœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚° ==="
    tail -n 20 logs/error.log
}

# æœ€å°é™å¾©æ—§
minimal_recovery() {
    echo "ğŸ› ï¸  æœ€å°é™å¾©æ—§é–‹å§‹"
    
    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    sqlite3 fastmcp.db "PRAGMA integrity_check;"
    
    # 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    python scripts/validate_config.py
    
    # 3. æœ€å°æ§‹æˆã§ã®èµ·å‹•
    python src/main.py --minimal --debug &
    
    # 4. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    sleep 10
    curl -f http://localhost:8000/health || echo "å¾©æ—§å¤±æ•—"
}
```

## 5. åˆå­¦è€…å‘ã‘é‹ç”¨æ”¯æ´

### 5.1 å­¦ç¿’ç’°å¢ƒãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹
```python
# learning_maintenance.py
class LearningEnvironmentMaintainer:
    """å­¦ç¿’ç’°å¢ƒãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹"""
    
    async def daily_maintenance(self):
        """æ—¥æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹"""
        maintenance_tasks = [
            self.clean_expired_sessions,
            self.update_tutorial_statistics,
            self.backup_learning_progress,
            self.optimize_learning_database,
            self.generate_learning_report
        ]
        
        results = {}
        for task in maintenance_tasks:
            try:
                result = await task()
                results[task.__name__] = {"status": "success", "result": result}
            except Exception as e:
                results[task.__name__] = {"status": "error", "error": str(e)}
        
        return results
    
    async def clean_expired_sessions(self):
        """æœŸé™åˆ‡ã‚Œã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        conn = sqlite3.connect("fastmcp.db")
        cursor = conn.cursor()
        
        # 24æ™‚é–“ä»¥ä¸Šéã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤
        cursor.execute("""
            DELETE FROM user_sessions 
            WHERE last_activity < datetime('now', '-24 hours')
        """)
        
        cleaned_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        return f"Cleaned {cleaned_count} expired sessions"
    
    async def update_tutorial_statistics(self):
        """ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«çµ±è¨ˆã®æ›´æ–°"""
        conn = sqlite3.connect("fastmcp.db")
        cursor = conn.cursor()
        
        # å®Œäº†ç‡çµ±è¨ˆã®æ›´æ–°
        cursor.execute("""
            UPDATE tutorials SET 
                completion_rate = (
                    SELECT CAST(COUNT(*) AS FLOAT) / 
                           (SELECT COUNT(*) FROM users) * 100
                    FROM user_progress 
                    WHERE tutorial_id = tutorials.id AND status = 'completed'
                ),
                average_time = (
                    SELECT AVG(completion_time)
                    FROM user_progress 
                    WHERE tutorial_id = tutorials.id AND status = 'completed'
                )
        """)
        
        conn.commit()
        conn.close()
        
        return "Tutorial statistics updated"
    
    async def generate_learning_report(self):
        """å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        conn = sqlite3.connect("fastmcp.db")
        cursor = conn.cursor()
        
        # åŸºæœ¬çµ±è¨ˆ
        cursor.execute("SELECT COUNT(*) FROM users")
        total_users = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM user_progress WHERE status = 'completed'")
        completed_tutorials = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM user_progress WHERE status = 'in_progress'")
        active_learners = cursor.fetchone()[0]
        
        report = {
            "date": datetime.now().strftime("%Y-%m-%d"),
            "total_users": total_users,
            "completed_tutorials": completed_tutorials,
            "active_learners": active_learners,
            "completion_rate": completed_tutorials / max(total_users, 1) * 100
        }
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(f"reports/learning_report_{report['date']}.json", "w") as f:
            json.dump(report, f, indent=2)
        
        conn.close()
        return f"Learning report generated: {report}"
```

### 5.2 é‹ç”¨è‡ªå‹•åŒ–
```bash
# automation.sh - é‹ç”¨è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

# å®šæœŸå®Ÿè¡Œè¨­å®š (cron)
setup_automation() {
    echo "âš™ï¸  é‹ç”¨è‡ªå‹•åŒ–è¨­å®š"
    
    # crontabã‚¨ãƒ³ãƒˆãƒªä½œæˆ
    cat > fastmcp_cron << EOF
# FastMCP Starter é‹ç”¨è‡ªå‹•åŒ–
# æ¯æ™‚ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
0 * * * * /path/to/fastmcp/scripts/health_check.sh

# æ—¥æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ (AM 2:00)
0 2 * * * /path/to/fastmcp/scripts/daily_maintenance.sh

# é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ (æ—¥æ›œæ—¥ AM 3:00)
0 3 * * 0 /path/to/fastmcp/scripts/weekly_report.sh

# ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ (æ—¥æ¬¡ AM 1:00)
0 1 * * * /path/to/fastmcp/scripts/rotate_logs.sh
EOF

    # crontabã«ç™»éŒ²
    crontab fastmcp_cron
    echo "âœ… è‡ªå‹•åŒ–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®šå®Œäº†"
}

# é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
weekly_report() {
    echo "ğŸ“Š é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­..."
    
    report_date=$(date +%Y-%m-%d)
    report_file="reports/weekly_report_$report_date.md"
    
    cat > "$report_file" << EOF
# FastMCP Starter é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ - $report_date

## ã‚µãƒ¼ãƒãƒ¼ç¨¼åƒçŠ¶æ³
- ç¨¼åƒæ™‚é–“: $(uptime -p)
- CPUå¹³å‡ä½¿ç”¨ç‡: $(get_avg_cpu_usage)%
- ãƒ¡ãƒ¢ãƒªå¹³å‡ä½¿ç”¨ç‡: $(get_avg_memory_usage)%

## å­¦ç¿’æ´»å‹•çµ±è¨ˆ
$(python scripts/generate_learning_stats.py)

## ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šã‚µãƒãƒªãƒ¼
$(analyze_error_logs)

## æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
$(generate_recommendations)
EOF

    echo "âœ… é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: $report_file"
}
```

## 6. æ›´æ–°å±¥æ­´

| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | æ›´æ–°æ—¥ | æ›´æ–°è€… | æ›´æ–°å†…å®¹ | å½±éŸ¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ |
|---|-----|-----|----|----|
| 1.0 | 2025-06-23 | mcp starter | åˆç‰ˆä½œæˆï¼ˆFastMCPå¯¾å¿œé‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã®ç­–å®šï¼‰ | 02_monitoring_backup.md, 03_migration_plan.md | 