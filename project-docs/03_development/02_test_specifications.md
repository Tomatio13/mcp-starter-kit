---
title: "ãƒ†ã‚¹ãƒˆä»•æ§˜"
version: "1.0"
last_updated: "2025-06-23"
author: "mcp starter"
reviewers: []
related_docs: ["01_development_standards.md", "02_application_design.md", "03_functional_requirements.md"]
status: "approved"
dependencies:
  upstream: ["01_development_standards.md", "02_design/02_application_design.md", "01_requirements/03_functional_requirements.md"]
  downstream: ["03_deployment_guide.md"]
impact_level: "high"
---

# ãƒ†ã‚¹ãƒˆä»•æ§˜

## 1. æ¦‚è¦

### 1.1 ç›®çš„
æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€FastMCPã‚¹ã‚¿ãƒ¼ã‚¿ãƒ¼ã‚­ãƒƒãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãŠã‘ã‚‹ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã€ãƒ†ã‚¹ãƒˆè¨­è¨ˆã€ãƒ†ã‚¹ãƒˆå®Ÿè£…ã®æŒ‡é‡ã‚’å®šç¾©ã—ã¾ã™ã€‚åˆå­¦è€…ãŒMCPã‚µãƒ¼ãƒé–‹ç™ºã«ãŠã„ã¦å“è³ªã®é«˜ã„ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã€ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºï¼ˆTDDï¼‰ã‚’å­¦ç¿’ã§ãã‚‹ç’°å¢ƒã‚’æä¾›ã—ã¾ã™ã€‚

### 1.2 é©ç”¨ç¯„å›²
- FastMCPãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ãŸMCPã‚µãƒ¼ãƒã®ãƒ†ã‚¹ãƒˆ
- SSEï¼ˆServer-Sent Eventsï¼‰ãŠã‚ˆã³STDIOé€šä¿¡æ–¹å¼ã®ä¸¡æ–¹ã®ãƒ†ã‚¹ãƒˆ
- åˆå­¦è€…å‘ã‘å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
- ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€ã‚µãƒ³ãƒ—ãƒ«ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ†ã‚¹ãƒˆ

### 1.3 ãƒ†ã‚¹ãƒˆç›®æ¨™
```yaml
å“è³ªç›®æ¨™:
  Code Coverage: â‰¥ 90%
  Bug Detection Rate: â‰¥ 95%
  Performance Regression: 0%
  Security Vulnerability: 0ä»¶

å­¦ç¿’ç›®æ¨™:
  TDDæ‰‹æ³•ã®ç¿’å¾—: åŸºæœ¬â†’å¿œç”¨
  ãƒ†ã‚¹ãƒˆè¨­è¨ˆã‚¹ã‚­ãƒ«: åŸºç¤â†’å®Ÿè·µ
  å“è³ªæ„è­˜ã®å‘ä¸Š: æ¦‚å¿µâ†’å®Ÿè£…
  è‡ªå‹•åŒ–ç†è§£: æ‰‹å‹•â†’è‡ªå‹•
```

## 2. ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 2.1 ãƒ†ã‚¹ãƒˆãƒ”ãƒ©ãƒŸãƒƒãƒ‰
```
        E2Eãƒ†ã‚¹ãƒˆ (10%)
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  çµ±åˆãƒ†ã‚¹ãƒˆ (20%)  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”Œâ”€â”€â”€ ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ (70%) â”€â”€â”€â”€â”
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ãƒ¬ãƒ™ãƒ«åˆ¥ç‰¹å¾´:
- ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ: é«˜é€Ÿãƒ»å®‰å®šãƒ»é–‹ç™ºè€…å‘ã‘
- çµ±åˆãƒ†ã‚¹ãƒˆ: ä¸­é€Ÿãƒ»æ©Ÿèƒ½æ¤œè¨¼ãƒ»QAå‘ã‘  
- E2Eãƒ†ã‚¹ãƒˆ: ä½é€Ÿãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ãƒ»å—å…¥ã‚Œå‘ã‘
```

### 2.2 ãƒ†ã‚¹ãƒˆåˆ†é¡
```yaml
æ©Ÿèƒ½åˆ¥ãƒ†ã‚¹ãƒˆ:
  MCP Protocol: 
    - Toolså®Ÿè¡Œãƒ†ã‚¹ãƒˆ
    - Resourceså–å¾—ãƒ†ã‚¹ãƒˆ
    - Promptsç”Ÿæˆãƒ†ã‚¹ãƒˆ
    - é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒ†ã‚¹ãƒˆ
  
  Transport Layer:
    - SSEé€šä¿¡ãƒ†ã‚¹ãƒˆ
    - STDIOé€šä¿¡ãƒ†ã‚¹ãƒˆ
    - æ¥ç¶šç®¡ç†ãƒ†ã‚¹ãƒˆ
    - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
  
  Learning System:
    - ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å®Ÿè¡Œãƒ†ã‚¹ãƒˆ
    - ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¿½è·¡ãƒ†ã‚¹ãƒˆ
    - å­¦ç¿’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ†ã‚¹ãƒˆ
    - åˆå­¦è€…æ”¯æ´æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

å“è³ªåˆ¥ãƒ†ã‚¹ãƒˆ:
  Performance: ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãƒ»ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
  Security: èªè¨¼ãƒ»èªå¯ãƒ»å…¥åŠ›æ¤œè¨¼
  Usability: åˆå­¦è€…ä½“é¨“ãƒ»æ“ä½œæ€§
  Reliability: éšœå®³å›å¾©ãƒ»å®‰å®šæ€§
  Compatibility: ç’°å¢ƒãƒ»ãƒ–ãƒ©ã‚¦ã‚¶å¯¾å¿œ
```

### 2.3 ãƒ†ã‚¹ãƒˆç’°å¢ƒæˆ¦ç•¥
```python
# ãƒ†ã‚¹ãƒˆç’°å¢ƒè¨­å®š
class TestEnvironments:
    """ãƒ†ã‚¹ãƒˆç’°å¢ƒç®¡ç†"""
    
    UNIT = {
        "database": "sqlite:///:memory:",
        "transport": "mock",
        "external_apis": "mock",
        "isolation": True
    }
    
    INTEGRATION = {
        "database": "sqlite:///test_integration.db",
        "transport": "sse",  # å®Ÿéš›ã®é€šä¿¡ã‚’ãƒ†ã‚¹ãƒˆ
        "external_apis": "stub",
        "isolation": False
    }
    
    E2E = {
        "database": "sqlite:///test_e2e.db", 
        "transport": "both",  # SSE + STDIO
        "external_apis": "sandbox",
        "isolation": False
    }
```

## 3. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆä»•æ§˜

### 3.1 MCPãƒ„ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ
```python
import pytest
from unittest.mock import AsyncMock, patch
from src.features.tools.calculator import CalculatorTool
from src.core.protocol import MCPRequest, MCPResponse

class TestCalculatorTool:
    """è¨ˆç®—ãƒ„ãƒ¼ãƒ«ã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
    
    åˆå­¦è€…å‘ã‘ã®åŸºæœ¬çš„ãªMCPãƒ„ãƒ¼ãƒ«å®Ÿè£…ã‚’ãƒ†ã‚¹ãƒˆã—ã€
    ãƒ„ãƒ¼ãƒ«é–‹ç™ºã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’å­¦ç¿’ã§ãã¾ã™ã€‚
    """
    
    @pytest.fixture
    def calculator_tool(self):
        """ãƒ†ã‚¹ãƒˆç”¨è¨ˆç®—ãƒ„ãƒ¼ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        return CalculatorTool()
    
    @pytest.mark.asyncio
    async def test_addition_success(self, calculator_tool):
        """æ­£å¸¸ãªåŠ ç®—å‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""
        # Given: å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æº–å‚™
        params = {"a": 5, "b": 3, "operation": "add"}
        
        # When: ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œ
        result = await calculator_tool.execute(params)
        
        # Then: çµæœã®æ¤œè¨¼
        assert result["success"] is True
        assert result["value"] == 8
        assert "è¨ˆç®—çµæœ" in result["message"]
    
    @pytest.mark.asyncio
    async def test_division_by_zero_error(self, calculator_tool):
        """ã‚¼ãƒ­é™¤ç®—ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
        # Given: ã‚¼ãƒ­é™¤ç®—ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        params = {"a": 10, "b": 0, "operation": "divide"}
        
        # When & Then: ä¾‹å¤–ç™ºç”Ÿã®ç¢ºèª
        with pytest.raises(ValueError) as exc_info:
            await calculator_tool.execute(params)
        
        assert "ã‚¼ãƒ­ã§å‰²ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“" in str(exc_info.value)
    
    @pytest.mark.asyncio
    async def test_invalid_operation_error(self, calculator_tool):
        """ç„¡åŠ¹ãªæ¼”ç®—å­ã‚¨ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
        # Given: ç„¡åŠ¹ãªæ¼”ç®—å­
        params = {"a": 5, "b": 3, "operation": "invalid"}
        
        # When & Then: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ç¢ºèª
        result = await calculator_tool.execute(params)
        
        assert result["success"] is False
        assert "ç„¡åŠ¹ãªæ¼”ç®—å­" in result["error"]
    
    @pytest.mark.parametrize("a,b,op,expected", [
        (10, 5, "add", 15),
        (10, 5, "subtract", 5),
        (10, 5, "multiply", 50),
        (10, 5, "divide", 2.0),
    ])
    async def test_all_operations(self, calculator_tool, a, b, op, expected):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹å…¨æ¼”ç®—ã®æ¤œè¨¼"""
        params = {"a": a, "b": b, "operation": op}
        result = await calculator_tool.execute(params)
        
        assert result["success"] is True
        assert result["value"] == expected

# åˆå­¦è€…å‘ã‘ãƒ†ã‚¹ãƒˆãƒ˜ãƒ«ãƒ‘ãƒ¼
class LearningTestHelper:
    """å­¦ç¿’è€…å‘ã‘ãƒ†ã‚¹ãƒˆæ”¯æ´ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def create_basic_test_template(tool_name: str) -> str:
        """åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            tool_name: ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ãƒ„ãƒ¼ãƒ«å
            
        Returns:
            ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        """
        return f'''
import pytest
from src.features.tools.{tool_name.lower()} import {tool_name}Tool

class Test{tool_name}Tool:
    """
    {tool_name}ãƒ„ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹
    
    å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆï¼š
    1. @pytest.fixture ã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
    2. @pytest.mark.asyncio ã§éåŒæœŸãƒ†ã‚¹ãƒˆ
    3. Given-When-Then ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ†ã‚¹ãƒˆæ§‹é€ ã‚’æ˜ç¢ºåŒ–
    """
    
    @pytest.fixture
    def {tool_name.lower()}_tool(self):
        """ãƒ†ã‚¹ãƒˆç”¨{tool_name}ãƒ„ãƒ¼ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        return {tool_name}Tool()
    
    @pytest.mark.asyncio
    async def test_{tool_name.lower()}_success(self, {tool_name.lower()}_tool):
        """æ­£å¸¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # Given: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        params = {{"input": "test_value"}}
        
        # When: ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œ
        result = await {tool_name.lower()}_tool.execute(params)
        
        # Then: çµæœã®æ¤œè¨¼
        assert result["success"] is True
        # ã•ã‚‰ã«è©³ç´°ãªæ¤œè¨¼ã‚’è¿½åŠ ã—ã¦ãã ã•ã„
    
    @pytest.mark.asyncio
    async def test_{tool_name.lower()}_error(self, {tool_name.lower()}_tool):
        """ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        # Given: ç„¡åŠ¹ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        params = {{"input": None}}
        
        # When & Then: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ç¢ºèª
        with pytest.raises(ValueError):
            await {tool_name.lower()}_tool.execute(params)
'''
```

### 3.2 MCPãƒªã‚½ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
```python
class TestTutorialResource:
    """ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ãƒªã‚½ãƒ¼ã‚¹ã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    def tutorial_resource(self):
        """ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ãƒªã‚½ãƒ¼ã‚¹ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        return TutorialResource()
    
    @pytest.fixture
    def mock_database(self):
        """ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        with patch('src.utils.database.Database') as mock_db:
            mock_db.get_tutorial.return_value = {
                "id": "basic-mcp",
                "title": "MCPåŸºç¤ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«",
                "content": "# MCPå…¥é–€\n\nMCPã‚µãƒ¼ãƒã®åŸºæœ¬çš„ãªä½œã‚Šæ–¹...",
                "difficulty": "beginner",
                "estimated_time": 30
            }
            yield mock_db
    
    @pytest.mark.asyncio
    async def test_get_tutorial_success(self, tutorial_resource, mock_database):
        """ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å–å¾—æˆåŠŸã®ãƒ†ã‚¹ãƒˆ"""
        # Given: æœ‰åŠ¹ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ID
        tutorial_id = "basic-mcp"
        
        # When: ãƒªã‚½ãƒ¼ã‚¹ã®å–å¾—
        result = await tutorial_resource.get(tutorial_id)
        
        # Then: çµæœã®æ¤œè¨¼
        assert result["success"] is True
        assert result["data"]["id"] == tutorial_id
        assert "title" in result["data"]
        assert "content" in result["data"]
        mock_database.get_tutorial.assert_called_once_with(tutorial_id)
    
    @pytest.mark.asyncio
    async def test_get_tutorial_not_found(self, tutorial_resource, mock_database):
        """å­˜åœ¨ã—ãªã„ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        # Given: å­˜åœ¨ã—ãªã„ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ID
        mock_database.get_tutorial.return_value = None
        tutorial_id = "non-existent"
        
        # When: ãƒªã‚½ãƒ¼ã‚¹ã®å–å¾—
        result = await tutorial_resource.get(tutorial_id)
        
        # Then: ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ç¢ºèª
        assert result["success"] is False
        assert "è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" in result["error"]
```

### 3.3 é€šä¿¡ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ†ã‚¹ãƒˆ
```python
class TestTransportLayer:
    """é€šä¿¡ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
    
    @pytest.mark.asyncio
    async def test_sse_transport_connection(self):
        """SSEé€šä¿¡ã®æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        # Given: SSEãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆã®è¨­å®š
        transport = SSETransport(host="localhost", port=8000)
        
        # When: æ¥ç¶šã®ç¢ºç«‹
        with patch('uvicorn.run') as mock_uvicorn:
            await transport.start()
            
        # Then: æ­£ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ç¢ºèª
        mock_uvicorn.assert_called_once()
        args, kwargs = mock_uvicorn.call_args
        assert kwargs["host"] == "localhost"
        assert kwargs["port"] == 8000
    
    @pytest.mark.asyncio  
    async def test_stdio_transport_message_handling(self):
        """STDIOé€šä¿¡ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # Given: STDIOãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆã¨ãƒ¢ãƒƒã‚¯å…¥å‡ºåŠ›
        transport = STDIOTransport()
        
        with patch('sys.stdin') as mock_stdin, \
             patch('sys.stdout') as mock_stdout:
            
            # JSONRPCãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ¢ãƒƒã‚¯
            mock_stdin.readline.return_value = json.dumps({
                "jsonrpc": "2.0",
                "id": 1,
                "method": "tools/call",
                "params": {"name": "calculator", "arguments": {"a": 5, "b": 3}}
            })
            
            # When: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†
            await transport.handle_message()
            
            # Then: é©åˆ‡ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ç¢ºèª
            mock_stdout.write.assert_called()
            response = json.loads(mock_stdout.write.call_args[0][0])
            assert response["jsonrpc"] == "2.0"
            assert response["id"] == 1
```

## 4. çµ±åˆãƒ†ã‚¹ãƒˆä»•æ§˜

### 4.1 MCPé€šä¿¡çµ±åˆãƒ†ã‚¹ãƒˆ
```python
class TestMCPIntegration:
    """MCPé€šä¿¡ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    async def mcp_server(self):
        """ãƒ†ã‚¹ãƒˆç”¨MCPã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•"""
        server = MCPServer(
            transport="sse",
            host="localhost", 
            port=8001,
            database_url="sqlite:///test_integration.db"
        )
        await server.start()
        yield server
        await server.stop()
    
    @pytest.fixture
    def mcp_client(self):
        """ãƒ†ã‚¹ãƒˆç”¨MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
        return MCPClient(base_url="http://localhost:8001")
    
    @pytest.mark.asyncio
    async def test_tool_execution_via_sse(self, mcp_server, mcp_client):
        """SSEçµŒç”±ã§ã®ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµ±åˆãƒ†ã‚¹ãƒˆ"""
        # Given: ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•æ¸ˆã¿ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒæ¥ç¶š
        await mcp_client.connect()
        
        # When: ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œè¦æ±‚
        response = await mcp_client.call_tool(
            name="calculator",
            arguments={"a": 10, "b": 5, "operation": "multiply"}
        )
        
        # Then: æ­£ã—ã„çµæœã®å—ä¿¡ç¢ºèª
        assert response.success is True
        assert response.result == 50
        
        # æ¥ç¶šã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        await mcp_client.disconnect()
    
    @pytest.mark.asyncio
    async def test_resource_access_via_sse(self, mcp_server, mcp_client):
        """SSEçµŒç”±ã§ã®ãƒªã‚½ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # Given: æ¥ç¶šæ¸ˆã¿ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        await mcp_client.connect()
        
        # When: ãƒªã‚½ãƒ¼ã‚¹ã®å–å¾—è¦æ±‚
        response = await mcp_client.get_resource("tutorials/basic-mcp")
        
        # Then: ãƒªã‚½ãƒ¼ã‚¹å†…å®¹ã®ç¢ºèª
        assert response.success is True
        assert "content" in response.data
        assert "title" in response.data
        
        await mcp_client.disconnect()
```

### 4.2 å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ
```python
class TestLearningSystemIntegration:
    """å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    async def learning_system(self):
        """å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        system = LearningSystem(database_url="sqlite:///test_learning.db")
        await system.initialize()
        yield system
        await system.cleanup()
    
    @pytest.mark.asyncio
    async def test_tutorial_completion_workflow(self, learning_system):
        """ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å®Œäº†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # Given: æ–°è¦å­¦ç¿’è€…ã®ç™»éŒ²
        user_id = "test_user_001"
        await learning_system.register_user(user_id, "åˆå­¦è€…å¤ªéƒ")
        
        # When: ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã®é–‹å§‹
        tutorial = await learning_system.start_tutorial(user_id, "basic-mcp")
        assert tutorial.status == "in_progress"
        
        # ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®å®Ÿè¡Œã¨é€²æ—ç¢ºèª
        for step_id in tutorial.steps:
            # ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œ
            result = await learning_system.execute_step(user_id, step_id)
            assert result.success is True
            
            # é€²æ—ã®ç¢ºèª
            progress = await learning_system.get_progress(user_id)
            assert step_id in progress.completed_steps
        
        # Then: ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å®Œäº†ç¢ºèª
        final_status = await learning_system.get_tutorial_status(user_id, "basic-mcp")
        assert final_status == "completed"
        
        # ä¿®äº†è¨¼æ˜æ›¸ã®ç™ºè¡Œç¢ºèª
        certificate = await learning_system.get_certificate(user_id, "basic-mcp")
        assert certificate is not None
        assert certificate.user_id == user_id
```

## 5. ãƒ†ã‚¹ãƒˆè‡ªå‹•åŒ–

### 5.1 CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
```yaml
# .github/workflows/test.yml
name: FastMCP Starter Test Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, 3.10, 3.11]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Run unit tests
      run: |
        pytest tests/unit/ \
          --cov=src \
          --cov-report=xml \
          --cov-report=html \
          --junit-xml=test-results.xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  integration-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v3
      with:
        python-version: 3.11
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Run integration tests
      run: |
        pytest tests/integration/ \
          --junit-xml=integration-test-results.xml

  e2e-tests:
    runs-on: ubuntu-latest
    needs: integration-tests
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v3
      with:
        python-version: 3.11
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Run E2E tests
      run: |
        pytest tests/e2e/ \
          --junit-xml=e2e-test-results.xml \
          --timeout=300
```

### 5.2 ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
#!/bin/bash
# scripts/test.sh - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

echo "FastMCP Starter Test Runner"
echo "=========================="

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
export TEST_DATABASE_URL="sqlite:///:memory:"

# ãƒ†ã‚¹ãƒˆç¨®åˆ¥ã®é¸æŠ
test_type=${1:-"all"}

case $test_type in
    "unit")
        echo "Running unit tests..."
        pytest tests/unit/ \
            --cov=src \
            --cov-report=term-missing \
            --cov-report=html:htmlcov \
            -v
        ;;
    "integration") 
        echo "Running integration tests..."
        pytest tests/integration/ \
            --tb=short \
            -v
        ;;
    "e2e")
        echo "Running E2E tests..."
        pytest tests/e2e/ \
            --tb=short \
            --timeout=300 \
            -v
        ;;
    "performance")
        echo "Running performance tests..."
        pytest tests/performance/ \
            --benchmark-only \
            --benchmark-save=performance \
            -v
        ;;
    "all")
        echo "Running all tests..."
        
        # ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
        echo "1. Unit Tests"
        pytest tests/unit/ --cov=src --cov-report=term-missing -x
        
        # çµ±åˆãƒ†ã‚¹ãƒˆ
        echo "2. Integration Tests"
        pytest tests/integration/ -x
        
        # E2Eãƒ†ã‚¹ãƒˆ
        echo "3. E2E Tests"
        pytest tests/e2e/ --timeout=300 -x
        
        echo "All tests completed successfully!"
        ;;
    *)
        echo "Usage: $0 [unit|integration|e2e|performance|all]"
        exit 1
        ;;
esac

echo "Test execution completed!"
```

## 6. å“è³ªä¿è¨¼

### 6.1 ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™
```python
# coverageé…ç½® (.coveragerc)
[run]
source = src/
omit = 
    */tests/*
    */venv/*
    */migrations/*
    */scripts/*

[report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:

precision = 2
show_missing = True

[html]
directory = htmlcov
```

### 6.2 åˆå­¦è€…å‘ã‘ãƒ†ã‚¹ãƒˆæ”¯æ´
```python
class LearnerTestSupport:
    """åˆå­¦è€…å‘ã‘ãƒ†ã‚¹ãƒˆæ”¯æ´ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.test_templates = {}
        self.explanation_db = {}
    
    def generate_test_explanation(self, test_code: str) -> str:
        """ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã®è§£èª¬ã‚’ç”Ÿæˆ"""
        explanations = []
        
        if "@pytest.fixture" in test_code:
            explanations.append("""
            ğŸ”§ @pytest.fixture ã«ã¤ã„ã¦:
            ãƒ†ã‚¹ãƒˆã§ä½¿ç”¨ã™ã‚‹å…±é€šã®ãƒ‡ãƒ¼ã‚¿ã‚„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æº–å‚™ã™ã‚‹ä»•çµ„ã¿ã§ã™ã€‚
            è¤‡æ•°ã®ãƒ†ã‚¹ãƒˆã§åŒã˜ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’å†åˆ©ç”¨ã§ãã¾ã™ã€‚
            """)
        
        if "@pytest.mark.asyncio" in test_code:
            explanations.append("""
            âš¡ @pytest.mark.asyncio ã«ã¤ã„ã¦:
            éåŒæœŸé–¢æ•°ï¼ˆasync/awaitï¼‰ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã«å¿…è¦ãªãƒãƒ¼ã‚«ãƒ¼ã§ã™ã€‚
            MCPã‚µãƒ¼ãƒãƒ¼ã¯éåŒæœŸå‡¦ç†ã‚’å¤šç”¨ã™ã‚‹ãŸã‚é‡è¦ã§ã™ã€‚
            """)
        
        if "assert" in test_code:
            explanations.append("""
            âœ… assertæ–‡ã«ã¤ã„ã¦:
            ãƒ†ã‚¹ãƒˆã®æ¤œè¨¼ã‚’è¡Œã†æ–‡ã§ã™ã€‚æ¡ä»¶ãŒå½ã®å ´åˆã€ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã™ã€‚
            assert result == expected  # resultã¨expectedãŒç­‰ã—ã„ã“ã¨ã‚’ç¢ºèª
            """)
        
        return "\n".join(explanations)
    
    def suggest_test_improvements(self, test_code: str) -> List[str]:
        """ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã®æ”¹å–„ææ¡ˆ"""
        suggestions = []
        
        if "# Given" not in test_code:
            suggestions.append("Given-When-Then ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚¹ãƒˆã®æ§‹é€ ã‚’æ˜ç¢ºã«ã—ã¾ã—ã‚‡ã†")
        
        if not re.search(r'async def test_.*_error', test_code):
            suggestions.append("ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆã‚‚è¿½åŠ ã—ã¦ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†")
        
        if "@pytest.parametrize" not in test_code:
            suggestions.append("è¤‡æ•°ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ãŒã‚ã‚‹å ´åˆã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ãƒ†ã‚¹ãƒˆã‚’æ¤œè¨ã—ã¾ã—ã‚‡ã†")
        
        return suggestions
```

## 7. æ›´æ–°å±¥æ­´

| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | æ›´æ–°æ—¥ | æ›´æ–°è€… | æ›´æ–°å†…å®¹ | å½±éŸ¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ |
|---|-----|-----|----|----|
| 1.0 | 2025-06-23 | mcp starter | åˆç‰ˆä½œæˆï¼ˆFastMCPå¯¾å¿œãƒ†ã‚¹ãƒˆä»•æ§˜ã®ç­–å®šï¼‰ | 01_development_standards.md, 03_deployment_guide.md |